<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

	<!-- 百度统计 -->
	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?e31627579358722b9d300535c8206351";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>

  <!--Description-->
  

  <!--Author-->
  
  <meta name="author" content="Vodkazy">
  

  <!--Open Graph Title-->
  
      <meta property="og:title" content="实体链接研究概述">
  
  <!--Open Graph Description-->
  
  <!--Open Graph Site Name-->
  <meta property="og:site_name" content="想飞的小菜鸡">
  <!--Type page-->
  
      <meta property="og:type" content="article">
  
  <!--Page Cover-->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- Title -->
  
  <title>实体链接研究概述 - 想飞的小菜鸡</title>


  <link rel="shortcut icon" href="/../images/icon.ico">
  <!--font-awesome-->
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <!-- Custom CSS/Sass -->
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Nav -->
  <header class="site-header">
  <div class="header-inside">
    
    <div class="logo">
      <a href="/" rel="home">
        
        <img src="data:image/png;base64,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" data-original="https://cdn2.iconfinder.com/data/icons/weather-color-2/500/weather-01-128.png" alt="想飞的小菜鸡" height="60">
        
      </a>
    </div>
    <a class="header-name" href="/">
            <span>想飞的小菜鸡</span>
            的小窝
        </a>
    <!-- navbar -->
    <nav class="navbar">
      <!--  nav links -->
      <div class="collapse">
        <ul class="navbar-nav">
          
          
            <li>
              <a href="/.">
                
                  <i class="fa fa-home "></i>
                
                首页
              </a>
            </li>
          
            <li>
              <a href="/archives">
                
                  <i class="fa fa-archive "></i>
                
                目录
              </a>
            </li>
          
            <li>
              <a href="/project">
                
                  <i class="fa fa-folder-open "></i>
                
                代码库
              </a>
            </li>
          
            <li>
              <a href="/photo">
                
                  <i class="fa fa-photo "></i>
                
                相册薄
              </a>
            </li>
          
            <li>
              <a href="/lovetree">
                
                  <i class="fa fa-tree "></i>
                
                爱情树
              </a>
            </li>
          
            <li>
              <a href="/guestbook">
                
                  <i class="fa fa-edit "></i>
                
                留言板
              </a>
            </li>
          
            <li>
              <a href="/about">
                
                  <i class="fa fa-user "></i>
                
                关于我
              </a>
            </li>
          
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </nav>
    <div class="button-wrap">
      <button class="menu-toggle">Primary Menu</button>
    </div>
  </div>
</header>


  <!-- Main Content -->
  <div class="content-area">
  <div class="post">
    <!-- Post Content -->
    <div class="container">
      <article>
        <!-- Title date & tags -->
        <div class="post-header">
          <h1 class="entry-title">
            实体链接研究概述
            
          </h1>
         
        </div>
         <p class="a-posted-on">
          2018-12-28
          </p>
        <!-- Post Main Content -->
        <div class="entry-content">
          <p>本文主要介绍了实体链接的定义、研究内容以及技术路线。</p>
<a id="more"></a>
<!-- toc -->
<ul>
<li><a href="#自然语言处理">自然语言处理</a></li>
<li><a href="#实体链接">实体链接</a></li>
<li><a href="#传统的实体链接算法">传统的实体链接算法</a></li>
<li><a href="#命名实体识别">命名实体识别</a></li>
<li><a href="#传统的ner算法">传统的NER算法</a></li>
<li><a href="#关系抽取">关系抽取</a></li>
<li><a href="#基于知识图谱的问答">基于知识图谱的问答</a></li>
</ul>
<!-- tocstop -->
<p><img src="data:image/png;base64,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" data-original="4.jpg" alt=""></p>
<h2><span id="自然语言处理">自然语言处理</span></h2><p>自然语言处理(Natural Language Processing, NLP )算法是人工智能技术的一大分支，利用自然语言处理技术可以赋予计算机处理和分析自然语言的能力，高效的识别，整理，分析文本数据。自然语言处理技术涵盖了对文本信息进行分析的多个维度，包括信息抽取，情感分析，关系抽取等。命名实体是自然语言处理领域中，最基础也是最重要的概念之一。自然语言中的人名(Person, PER)、地理政治名(Geography and Political, GPE)和组织机构名(Organization, ORG)都是常见的命名实体，在更广义的定义下，命名实体甚至还包括日期和货币等。每个命名实体都与现实世界中的具体的事物或者概念相对应，这些概念中蕴含着重要的语义信息，因此命名实体相关的研究一直以来就是自然语言处理领域研究的基础和重点。</p>
<p>然而自然语言中存在着大量的简写、缩写、不规范和模糊的表达，同时许多实体存在着多词同义以及一词多义的情况，导致机器在处理非结构化的自由文本时无法确定实体确切的指代关系，影响了整个自然语言处理系统的性能。因此，解决实体的歧义性问题是非常有必要的。</p>
<h2><span id="实体链接">实体链接</span></h2><p>实体链接的目标就是解决实体间存在的歧义性问题。实体的歧义性体现在两个方面，第一，实体可能存在多词同义的情况，即一个实体可以用多个实体指称来表示，例如，实体指称<code>Cornell University</code>，和它的简写<code>Cornell</code>都可以表示康奈尔大学这一实体，<code>New York City</code>及其别名<code>Big Apple City</code>都表示纽约。同时，实体也有一词多义的现象，即同一个实体指称可以表示多个实体，例如，实体指称<code>“Sun”</code>能够表示太阳系中心的星球，也可以表示一个跨国的计算机公司。实体链接算法需要通过实体指称及其上下文的文本信息，借助目标知识图谱，将其链接到知识图谱中正确的映射实体上。</p>
<p>实体链接是一项将自由文本中的实体指称(entity mention)链接到目标知识图谱中对应的实体(entity)的任务。实体链接在英文、中文、以及跨语言的场景下都有相关研究，但由于大规模英文知识图谱的普及，目前主要以英文的实体链接研究为主。本文也主要关注实体链接在英文语料的研究。一般来说，实体链接可以划分为两个阶段的子任务:<strong>候选实体生成</strong>和<strong>候选实体排序</strong>。其中，候选实体生成可以利用实体词字典，或者根据表面形式匹配等方式从知识图谱中检索得到候选实体列表。而候选实体排序则是通过匹配相似度计算的方式，对候选实体列表进行排序。<br><img src="data:image/png;base64,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" data-original="1.png" alt=""><br>如图1-1所示，是一个与知识图谱Freebase进行实体链接的例子。在示例中，<code>Bill Clinton</code>是句子中的实体指称，在Freebase中，检索到多个符合的候选实体，最后根据Freebase中的信息以及实体指称的上下文，正确地将<code>Bill Clinton</code>链接到实体<code>&quot;/m/0157m&quot;</code>。由于在自然语言中一词多义、多词同义的现象的普遍存在，准确的衡量实体指称与候选实体之间匹配程度是很困难的，因此候选实体排序是目前实体链接算法研究的重点和难点，实体链接算法也一般是指候选实体排序算法。</p>
<h2><span id="传统的实体链接算法">传统的实体链接算法</span></h2><p>一般采用非结构化的知识图谱，典型的如维基百科，作为目标知识图谱，利用实体指称所在句子或者文档的上下文，以及维基百科中实体页面的文本信息，抽取特征向量计算相似度进行实体链接。按照是否需要标注训练数据，它可以分为<strong>有监督</strong>和<strong>无监督</strong>两类。有监督学习的方法需要依靠标注好的训练集，来训练相应的分类或排序算法。其中一些常见的特征包括实体流行度，语义关联特征以及用词袋模型表示的上下文向量计算出的文本相似度特征等。而无监督的方法不需要标注的训练集，往往利用一些统计层面的特征，缺乏语义层面的考虑，所以效果相对有监督的方法较差。</p>
<p>其中，有监督的方法又可以大致分为<strong>二值分类法</strong>、<strong>基于排序学习</strong>( Learning to Rank )的方法和<strong>基于图的方法</strong>这三类。二值分类的方法将候选实体排序问题当作一个二值分类的问题。此时的训练数据由一个(实体指称，候选实体)对<code>&lt;m，ei&gt;</code>构成，如果实体指称正确链接到ei，则实例被标注为正例，否则则为负例。算法将每个<code>&lt;m,ei&gt;</code>对表示为一个特征向量，然后利用二元<code>Logistic</code>,  <code>SVM</code>等分类器来进行学习，得到分类函数。二值分类法显而易见的缺点即是由于大部分候选实体都是负例样本，会造成训练数据非常不平衡，同时当一个实体指称的多个候选实体被分为正例时，需要借助额外的手段来进行区分。</p>
<p>排序学习的框架被广泛用于实体链接的候选实体排序子任务中。假设对于每个实体指称m，给定正确标注的映射实体<code>em</code>，则根据基于训练数据的最大间隔原理，正确映射实体的得分<code>Score(em)</code>应该比任何其他的候选实体<code>Score(ei)</code>要高一个间隔的分数。根据这个约束条件来训练分类器。在测试阶段则挑选得分最高的候选实体作为正确的链接实体。这类方法的主要区别在于特征向量的选取。Shen等人在实体链接系统LINDEN中，利用实体流行度、语义关联(例如基于维基百科的链接结构语义上下文相似度)、语义相似性(从YAGO分类派生的语义上下文相似性)和映射实体之间的全局主题一致性4种特征组成的特征向量，用排序学习的框架学习特征向量。</p>
<p>另一种基于图的方法将文档中的实体指称及其候选实体构建为图结构，利用实体指称间、候选实体间、实体指称与候选实体间的关联关系进行协同推理。Han等人构建了以实体指称和候选实体为节点，包含指称-实体、实体-实体关系的图，借助类似主题敏感的PageRank协同推理算法，得到实体指称所链接的实体。Hoffart等人在构建指称-候选实体图结构的基础上，用实体流行度、文本上下文相似度等对“实体指称-实体”边加权，用映射实体一致性对“实体-实体”边加权，然后计算对每个指称只包含一条实体指称一实体边的稠密子图，得到从实体指称到实体的映射结果。</p>
<p>此外，还可以将实体链接的方法分为<strong>独立链接</strong>与<strong>联合链接</strong>两大类。独立链接每次只考虑一个实体指称，而联合链接的方法则考虑同一篇文档中的实体指称一般都是互相影响的，能够互相提供实体链接的信息量，因此联合链接的方法同时考虑一篇文档中的所有实体指称。</p>
<p>同时，近年来神经网络，深度学习的方法以其端到端、无需人工特征工程等优良特性，迅速在计算机视觉，自然语言处理的一些任务上得到应用，并取得了优于传统方法的结果。实体链接领域也不例外，这类方法通过浅层的词向量或者神经网络模型，简化了实体链接方法中特征抽取的过程。Sun等人简单的将实体指称上下文，实体指称，候选实体词通过词向量的方式简单组合，在实体链接上取到了state-of-the-art的效果，这足见神经网络在实体链接任务上的巨大潜力。神经网络可以直接利用到训练语句中的信息，最大化保留实体所在句子的语义信息。而实体在知识图谱中的关系结构，是对实体词链接，消歧的很好的约束。同时还可以解决一些主体为结构化信息的知识图谱缺乏实体上下文信息的问题。</p>
<p>总结来看，传统的实体链接的研究多采用维基百科作为目标知识图谱，利用实体指称所在句子或者文档的上下文以及候选实体在维基百科中页面的文本信息，抽取两者的特征向量，利用特征向量来对候选实体进行排序，得到正确链接的实体。这样的做法有着<strong>明显的不足</strong>就是：</p>
<ol>
<li><p>在信息检索，自动问答等领域得到广泛应用的结构化知识图谱，例如Freebase、DBpedia等，缺少实体的上下文文本信息，无法用传统方法进行实体链接；</p>
</li>
<li><p>传统方法需要特别繁琐、耗时的人工特征抽取、筛选，而且这类特征往往停留在浅层特征上，比如字符串匹配等，往往只适用于某种特定的语料、场景，缺乏通用性，不能表示实体指称、实体真正的语义信息。</p>
</li>
</ol>
<h2><span id="命名实体识别">命名实体识别</span></h2><p>命名实体识别(Named Entity Recognition, NER)又被称为“专名识别”，是一项识别文本中包括人名、地名、机构名和专有名词等在内的具有特定含义的实体的任务。NER任务是自然语言处理研究的一个基础问题，包括实体边界识别、确定实体类别两部分的任务，通常可以将其作为序列标注问题来研究解决。更具体来说，NER属于序列标注中的Segment Classification问题，即对输入序列中的每个元素在输出序列中给出对应的标签。与分类问题相比，序列标注问题中，当前输入单元的预测结果不仅取决于当前的输入特征，还与之前单元的预测输出有关，即预测标签结果之间具有强相互依赖关系，之前的预测标签可以为之后的预测提供信息量。例如，假设文本标注是采用BIO标注法的，则进行NER时，正确的预测结果中，标签B是不会紧跟着出现在标签I之后的。BIO标注法中，原文本是观察序列X, B代表句子的开始，I代表句子中间，O代表句子结束，标识序列Y对应X序列的识别。如下图2-1所示，即是NER中一个标注结果的示例:<br><img src="data:image/png;base64,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" data-original="2.png" alt=""><br>最后我们可以根据序列标注结果可以直接得到实体边界和实体类别。</p>
<h2><span id="传统的ner算法">传统的NER算法</span></h2><p>早期的NER问题的解决思路主要是基于词典和手工编写的规则。这种方法存在两个明显的缺陷：首先，它无法识别新词；其次，规则的制定依赖于特定性的领域和专家，人力构建成本高而且迁移性差。由于这种基于词典和手工编写的规则的巨大局限性，已经慢慢被淘汰。</p>
<p>目前主流的命名实体识别方法主要是基于统计学习的方法，代表性的如<code>隐马尔可夫模型(Hidden Markov Model, HMM)</code>和<code>条件随机场(Conditional Random Field, CRF)</code>，以及近些年来随着深度学习方法在自然语言处理研究中的普及，出现的将<code>循环神经网络(Recurrent Neural Network, RNN)</code>与CRF结合的方法。这两种方法的最主要的优势就是无需庞大的字典和知识图谱，只需要在人工标注好的训练集上练出模型即可进行命名实体识别，而且还具有速度快，可移植性强等优点。</p>
<p>基于统计学习的方法，本质上是一个条件概率模型。以CRF为例，如下图2-2所示，是用CRF进行NER的例子，其中x表示观测到的输入词序列，xi表示第i个词，yi表示对应的预测标签。给定一个观测的输入词序列，CRF产生该输入序列对应的概率最高的标签序列。CRF综合考虑输入的状态特征函数和标签转移的特征函数，来制定目标函数。在训练阶段，CRF采用<code>随机梯度下降(Stochastic Gradient Descent，SGD)算法</code>进行参数的学习和更新。而在预测阶段，可以看作是动态规划的问题，即对于给定的输入序列，求使目标函数最大的输出标签序列，可以采用维特比算法进行解码。<br><img src="data:image/png;base64,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" data-original="3.png" alt=""></p>
<p>以CRF为代表的基于统计学习的模型大多只能使用局部信息或需要人工设计特征。而RNN等序列模型可以处理序列元素之间前后关联问题，能够从原始输入文本中学习特征表示，因此更加适合序列标注任务。随着深度学习研究的发展，这类神经网络模型应用越来越广泛。这类方法的通用框架是:使用RNN网络学习输入词序列的特征，将学习到的特征接入CRF完成序列标注，实际上是将传统CRF中的线性模型换成了非线性神经网络。其中，代表性的研究是Ma等人做出的工作。实验结果表明，这类基于神经网络的NER方法以及达到甚至超过了传统的CRF模型。这种方法使用简单的词向量或者字符向量作为输入，无需繁杂的特征工程，可以基于此构建端到端的NER系统，己经成为NER研究的首选方法。</p>
<h2><span id="关系抽取">关系抽取</span></h2><p>在得到原始问题的主题实体e之后，可以选取知识图谱中e直接相连的所有关系作为候选关系集合。在关系抽取模块中，通过向量建模的方法，将问题编码成包含语义信息的分布式表示，与处于同一语义向量空间的候选关系向量一一计算相似度，选择相似度最高的关系作为问题的关系类型。在训练过程中，对于候选关系的特征向量，可以采用随机初始化的方式，或者用<code>TransE</code>预训练得到的关系向量作为初始化向量，并在更新模型参数时同时迭代训练更新关系向量。训练结束之后，训练好的关系向量可以直接用于之后的预测。<br>因此，如何更准确的抽取问题句子的特征表示向量是整个模块的关键。在自然语言中，不同的关系类型往往是具有不同的语法搭配的。因此用人的思维方式来判断，能够体现句子中实体与实体之间的关系类型的，并不仅仅只有句子中的词汇信息，还包括句子中的句法依存信息，尤其是实体与实体之间的不同的语法搭配信息，具体在问答的场景下，即是疑问词与主题实体的依存路径。另一方面，组成句子的单词中，并不是每个词对于关系抽取都提供相同的信息量，还是用<code>Who is the director of Avatar</code>来举例，在这个例子中，<code>director</code>对于判断关系类型的贡献显然是最大的。因此在关系抽取的研究中，引入注意力机制，可以有效的增大与关系直接相关的词向量的权重，提升关系抽取算法的准确率。近年来，基于神经网络的方法在关系抽取的问题上取得了很大的成功。这些方法利用CNN或者RNN网络对句子进行编码，并用得到的特征向量进行关系分类。</p>
<p>参考Xu和Liu利用句子的句法信息进行关系抽取的研究，他们利用CNN对问题中疑问词到主题实体的依存路径进行编码，得到问题句法层面的特征向量(syntactic feature )；最后将词汇特征向量与句法特征向量拼接作为问题最终的特征向量，与候选的关系向量点乘计算相似度，相似度最高的即可认为是问题的关系。</p>
<h2><span id="基于知识图谱的问答">基于知识图谱的问答</span></h2><p>自动问答技术是当前自然语言处理领域一个非常热门的研究方向，它综合运用了各种自然语言处理技术，包括语言分析、信息检索、知识表示学习等等。传统的搜索引擎对于用户的提问，只返回相关的网页，用户需要结合自身的知识筛选定位所需的信息。而自动问答系统可以视为新一代的搜索引擎，它不要求用户将问题拆分为关键字，针对完整的问题句子，问答系统通过语义分析理解，从各种数据资源中自动查找，并直接返回给用户想要的答案。问答系统按照功能形式，可以分为开放域问答和限定域问答。</p>
<p>开放域是指系统对于用户的提问问题所属领域不加限定，系统从海量数据分析、抽取得到直接的答案;限定域是指系统只能针对性的回答预先定义好的某个垂直领域的问题，其他领域的问题无法回答。而按照使用的数据资源来划分，问答系统又可以分为基于结构化数据的问答系统和基于非结构化数据的问答系统。随着近年来Freebase, YAG02, DBpedia等大规模结构化知识库的发展，自动问答技术得到巨大的提升，基于知识图谱的问答(Knowledge Based Question Answer, KB-QA)成为自动问答领域的研究热点。</p>
<p>KB-QA，即对于自然语言形式的问题，通过语义理解等技术手段分析，进而利用知识图谱进行查询、推理得到直接答案。KB-QA的发展经历了早期的特定领域的研究到目前基于大规模知识图谱的研究。KB-QA系统可以看作是一个特殊的对话系统，但和传统的对话系统相比，KB-QA只需要考虑当前问题，答案存在于知识图谱的实体或实体关系中，而对话系统则需要考虑上下文语境，以自然语言句子作为回复内容。同时，KB一QA的评价指标主要看<strong>召回率</strong>、<strong>准确率</strong>和<strong>F1值</strong>等类似于分类的指标，而对话系统的效果主要依靠人工评估。</p>
<p>KBQA的传统主流方法可以概括为以下三类:</p>
<ul>
<li>基于语义解析的方法。这种方法是一种基于语言学的方法，通过句法依存分析等方法将自然语言转化为形式化的逻辑形式(logic form)，然后再对逻辑形式自底向上进行解析，得到包含问题句子语义信息的逻辑表达式。最后再根据逻辑表达式构建相应的查询语句在知识图谱中进行查询，从而得到问题的答案。</li>
<li>基于信息抽取的方法。这类方法的主体思想是通过抽取问题中的主题实体，并在知识图谱中查询该实体，得到以该实体节点为中心的知识子图，将该子图中的所有节点、边作为候选答案。然后依据定义好的规则或模板抽取得到问题句子的特征向量，并根据输入问题的特征向量训练分类器来对候选答案进行筛选，得到最后的答案。</li>
<li>基于向量建模的方法。基于向量建模方法的原理比较类似于基于信息抽取的方法，不同的是，在得到问题的候选答案之后，它把问题和候选答案都映射为分布式表达(Distributed Representation)，使得问题和正确答案的特征向量的相似度得分(通常计算两者的向量点乘)尽量高。通过这种方式训练得到问题句子和候选实体的表示向量，在之后的预测阶段，则可一一计算问题的特征向量与每个候选答案的得分进行排序，选择相似度得分最高的作为最终答案。</li>
</ul>
<p>随着近年来深度学习的飞速发展，神经网络模型被广泛应用到自然语言处理的研究中。从2015年开始，开始出现用神经网络进行知识图谱问答的研究。这类方法通过结合神经网络与传统的方法，在KB-QA系统上取得了很好的效果。Yih等人用卷积神经网络将问题的逻辑形式进行编码，有效的提升了语义解析方法的效率。同样的，深度学习也被用到基于向量建模的KB-QA方法中，这些改进方法的主要区别在于它们所用到的网络结构，如利用记忆网络(memory network)学习句子和知识库实体、关系的表示。</p>
<blockquote>
<p>本文来源：「想飞的小菜鸡」的个人网站  <a href="https://vodkazy.cn" target="_blank" rel="noopener">vodkazy.cn</a></p>
<p>版权声明：本文为「想飞的小菜鸡」的原创文章，采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请附上原文出处链接及本声明。</p>
<p>原文链接：<a href="https://vodkazy.cn/2018/12/28/实体链接研究概述" target="_blank" rel="noopener">https://vodkazy.cn/2018/12/28/实体链接研究概述</a></p>
</blockquote>

        </div>
      </article>
    </div>

	<!-- 打赏 -->
    <div class="reward">
	<div class="reward-button">赏 <span class="reward-code">
		<span class="alipay-code"> <img class="alipay-img wdp-appear" src="data:image/png;base64,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" data-original="/images/alipay.webp"><b>支付宝打赏</b> </span> 
		<span class="wechat-code"> <img class="wechat-img wdp-appear" src="data:image/png;base64,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" data-original="/images/weixin.webp"><b>微信打赏</b> </span> </span>
	</div>
	<p class="reward-notice">如果文章对你有帮助，欢迎点击上方按钮打赏作者，更多文章请访问<a href="https://vodkazy.cn" style="color:blue">想飞的小菜鸡</a></p>
	    <style>
		*,*:before,*:after {
			-webkit-box-sizing: border-box;
			-moz-box-sizing: border-box;
			-ms-box-sizing: border-box;
			box-sizing: border-box
		}

		.reward {
			padding: 5px 0
		}

		.reward .reward-notice {
			font-size: 14px;
			line-height: 14px;
			margin: 15px auto;
			text-align: center
		}

		.reward .reward-button {
			font-size: 28px;
			line-height: 58px;
			position: relative;
			display: block;
			width: 60px;
			height: 60px;
			margin: 0 auto;
			padding: 0;
			-webkit-user-select: none;
			text-align: center;
			vertical-align: middle;
			color: #fff;
			border: 1px solid #f1b60e;
			border-radius: 50%;
			background: #fccd60;
			background: -webkit-gradient(linear,left top,left bottom,color-stop(0,#fccd60),color-stop(100%,#fbae12),color-stop(100%,#2989d8),color-stop(100%,#207cca));
			background: -webkit-linear-gradient(top,#fccd60 0,#fbae12 100%,#2989d8 100%,#207cca 100%);
			background: linear-gradient(to bottom,#fccd60 0,#fbae12 100%,#2989d8 100%,#207cca 100%)
		}

		.reward .reward-code {
			position: absolute;
			top: -220px;
			left: 50%;
			display: none;
			width: 350px;
			height: 200px;
			margin-left: -175px;
			padding: 15px;
			border: 1px solid #e6e6e6;
			background: #fff;
			box-shadow: 0 1px 1px 1px #efefef
		}

		.reward .reward-button:hover .reward-code {
			display: block
		}

		.reward .reward-code span {
			display: inline-block;
			width: 150px;
			height: 150px
		}

		.reward .reward-code span.alipay-code {
			float: left
		}

		.reward .reward-code span.alipay-code a {
			padding: 0
		}

		.reward .reward-code span.wechat-code {
			float: right
		}

		.reward .reward-code img {
			display: inline-block;
			float: left;
			width: 150px;
			height: 150px;
			margin: 0 auto;
			border: 0
		}

		.reward .reward-code b {
			font-size: 14px;
			line-height: 26px;
			display: block;
			margin: 0;
			text-align: center;
			color: #666
		}

		.reward .reward-code b.notice {
			line-height: 2rem;
			margin-top: -1rem;
			color: #999
		}

		.reward .reward-code:after,.reward .reward-code:before {
			position: absolute;
			content: '';
			border: 10px solid transparent
		}

		.reward .reward-code:after {
			bottom: -19px;
			left: 50%;
			margin-left: -10px;
			border-top-color: #fff
		}

		.reward .reward-code:before {
			bottom: -20px;
			left: 50%;
			margin-left: -10px;
			border-top-color: #e6e6e6
		}
    </style>


    <!-- Pre or Next -->
    
	<div class="container">
           <ul class="pager">
    	     
      	     <li class="previous">
              <a href="/2018/12/30/吴恩达CS229机器学习笔记（一）/" rel="prev">上一篇</a>
             </li>
           
           
              <li class="next">
              <a href="/2018/12/22/LC-QuAD数据集调研报告/" rel="prev">下一篇</a>
            </li>
           
          </ul>
       </div>
   

    <!-- Valine无后端评论系统 -->   
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
    <div id="vcomments"></div>
    <script>
        new Valine({
		    el: '#vcomments' ,
		    appId: 'lH3VkMCd4MHaKtr2n2SRWdoi-MdYXbMMI',
		    appKey: '5aMXSY7b4KwnzfgpzLA0hPLv',
		    notify:true, 
		    verify:false, 
		    placeholder: '填写正确的邮箱和昵称才能收到我的回复哦       ٩( ^o^ )و  ' ,
		    avatar: 'retro'
		});
    </script>
    <!-- Valine无后端评论系统 -->  

  </div>
</div>
</div>

  <!-- Footer -->
  <!-- Footer -->
<footer class="site-info">
  <p>
    <span>想飞的小菜鸡 &copy; 2021</span>
    
      <span class="split">|</span>
      <span>照耀的Blog</span>
    
  </p>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
    本站访客数<span id="busuanzi_value_site_uv"></span>人次
    本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</footer>

  <!-- After footer scripts -->
  <!-- scripts -->
<script src="/js/app.js"></script>


 
  <!-- 使用 aotuload.js 引入看板娘 -->    
  <!-- //<script src="/js/assets/jquery.min.js?v=3.3.1"></script> -->   
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
  <!-- //<script src="/js/assets/jquery-ui.min.js?v=1.12.1"></script>   --> 
  <script src="https://cdn.jsdelivr.net/npm/jquery-ui-dist@1.12.1/jquery-ui.min.js"></script>
  <script src="/js/assets/autoload.js?v=1.4.2"></script>
  <!-- //<script src="https://live2d-cdn.fghrsh.net/assets/1.4.2/autoload.js></script> --><!-- hexo-inject:begin --><!-- hexo-inject:end -->   
   


<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],e=void 0,0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>

</html>
