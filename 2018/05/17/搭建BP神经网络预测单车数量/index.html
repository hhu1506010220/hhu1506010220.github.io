<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

	<!-- 百度统计 -->
	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?e31627579358722b9d300535c8206351";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>

  <!--Description-->
  

  <!--Author-->
  
  <meta name="author" content="Vodkazy">
  

  <!--Open Graph Title-->
  
      <meta property="og:title" content="搭建BP神经网络预测单车数量">
  
  <!--Open Graph Description-->
  
  <!--Open Graph Site Name-->
  <meta property="og:site_name" content="想飞的小菜鸡">
  <!--Type page-->
  
      <meta property="og:type" content="article">
  
  <!--Page Cover-->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- Title -->
  
  <title>搭建BP神经网络预测单车数量 - 想飞的小菜鸡</title>


  <link rel="shortcut icon" href="/../images/icon.ico">
  <!--font-awesome-->
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <!-- Custom CSS/Sass -->
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Nav -->
  <header class="site-header">
  <div class="header-inside">
    
    <div class="logo">
      <a href="/" rel="home">
        
        <img src="data:image/png;base64,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" data-original="https://cdn2.iconfinder.com/data/icons/weather-color-2/500/weather-01-128.png" alt="想飞的小菜鸡" height="60">
        
      </a>
    </div>
    <a class="header-name" href="/">
            <span>想飞的小菜鸡</span>
            的小窝
        </a>
    <!-- navbar -->
    <nav class="navbar">
      <!--  nav links -->
      <div class="collapse">
        <ul class="navbar-nav">
          
          
            <li>
              <a href="/.">
                
                  <i class="fa fa-home "></i>
                
                首页
              </a>
            </li>
          
            <li>
              <a href="/archives">
                
                  <i class="fa fa-archive "></i>
                
                目录
              </a>
            </li>
          
            <li>
              <a href="/project">
                
                  <i class="fa fa-folder-open "></i>
                
                代码库
              </a>
            </li>
          
            <li>
              <a href="/photo">
                
                  <i class="fa fa-photo "></i>
                
                相册薄
              </a>
            </li>
          
            <li>
              <a href="/lovetree">
                
                  <i class="fa fa-tree "></i>
                
                爱情树
              </a>
            </li>
          
            <li>
              <a href="/guestbook">
                
                  <i class="fa fa-edit "></i>
                
                留言板
              </a>
            </li>
          
            <li>
              <a href="/about">
                
                  <i class="fa fa-user "></i>
                
                关于我
              </a>
            </li>
          
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </nav>
    <div class="button-wrap">
      <button class="menu-toggle">Primary Menu</button>
    </div>
  </div>
</header>


  <!-- Main Content -->
  <div class="content-area">
  <div class="post">
    <!-- Post Content -->
    <div class="container">
      <article>
        <!-- Title date & tags -->
        <div class="post-header">
          <h1 class="entry-title">
            搭建BP神经网络预测单车数量
            
          </h1>
         
        </div>
         <p class="a-posted-on">
          2018-05-17
          </p>
        <!-- Post Main Content -->
        <div class="entry-content">
          <p>利用简单的三层bp神经网络进行共享单车的预测。<br><a id="more"></a></p>
<p>直接上代码。模块解释都写在了代码里面。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data_path = <span class="string">'Bike-Sharing-Dataset/hour.csv'</span></span><br><span class="line">rides = pd.read_csv(data_path)</span><br><span class="line"><span class="comment"># 用于处理还有表头的</span></span><br><span class="line">rides.head()</span><br><span class="line"><span class="comment"># 从第1行读到第240行</span></span><br><span class="line">rides[:<span class="number">24</span>*<span class="number">10</span>].plot(x=<span class="string">'dteday'</span>, y=<span class="string">'cnt'</span>)</span><br><span class="line"><span class="comment"># 用xx.xx来引用表中元素 用plt.plot(rides.dteday,rides.cnt)画图</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line">dummies_fields = [<span class="string">'season'</span>, <span class="string">'hr'</span>, <span class="string">'mnth'</span>, <span class="string">'weekday'</span>, <span class="string">'weathersit'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> dummies_fields:</span><br><span class="line">    <span class="comment"># 将each所在列变量转换成新增的虚拟变量 如season(值有1~4)变为season1~season4</span></span><br><span class="line">    dummies = pd.get_dummies( rides.loc[:, each], prefix=each )</span><br><span class="line">    <span class="comment"># axis=0为行1为列 将dummies接到rides的最后面一列</span></span><br><span class="line">    rides = pd.concat( [rides, dummies], axis=<span class="number">1</span> )</span><br><span class="line"></span><br><span class="line">drop_fields = [ <span class="string">'season'</span>, <span class="string">'hr'</span>, <span class="string">'mnth'</span>, <span class="string">'weekday'</span>, <span class="string">'weathersit'</span>, <span class="string">'instant'</span>, <span class="string">'dteday'</span>, <span class="string">'atemp'</span> ]</span><br><span class="line"><span class="comment"># 按axis=1（列）删除数据</span></span><br><span class="line">data = rides.drop(drop_fields, axis=<span class="number">1</span>)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line">standard_field = [<span class="string">'temp'</span>, <span class="string">'hum'</span>, <span class="string">'windspeed'</span>, <span class="string">'casual'</span>, <span class="string">'registered'</span>, <span class="string">'cnt'</span>]</span><br><span class="line">scaled_feature = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> standard_field:</span><br><span class="line">    <span class="comment"># mean()方法求均值 std方法求标准差(默认除以n-1)</span></span><br><span class="line">    mean, std = data[each].mean(), data[each].std()</span><br><span class="line">    scaled_feature[each] = [mean, std]</span><br><span class="line">    <span class="comment"># 使用z-score方法进行规范化 得到的结果是每列所有数据都聚集在0附近，方差为1</span></span><br><span class="line">    data.loc[:, each] = (data.loc[:,each] - mean) / std</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save data for approximately 21 days 最末尾的21天作为测试集</span></span><br><span class="line">test_data = data[<span class="number">-21</span>*<span class="number">24</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留第1条到第倒数21*24之前的数据</span></span><br><span class="line">data = data[:<span class="number">-21</span>*<span class="number">24</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data into features and targets</span></span><br><span class="line">target_fields = [<span class="string">'cnt'</span>, <span class="string">'casual'</span>, <span class="string">'registered'</span>]</span><br><span class="line"><span class="comment"># 这三列targets作为输出层 其他的features作为输入层</span></span><br><span class="line">features = data.drop( target_fields, axis=<span class="number">1</span> )</span><br><span class="line">targets = data.loc[:, target_fields]</span><br><span class="line"></span><br><span class="line">test_features = test_data.drop( target_fields, axis=<span class="number">1</span> )</span><br><span class="line">test_targets = test_data.loc[:, target_fields]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后60天之前作为训练集  最后60天作为验证集</span></span><br><span class="line">train_features, train_targets = features[:<span class="number">-60</span>*<span class="number">24</span>], targets[:<span class="number">-60</span>*<span class="number">24</span>]</span><br><span class="line">val_features, val_targets = features[<span class="number">-60</span>*<span class="number">24</span>:], targets[<span class="number">-60</span>*<span class="number">24</span>:]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, input_nodes, hidden_nodes, output_nodes, learning_rate )</span>:</span></span><br><span class="line">        <span class="comment"># Set the number of nodes in input, hidden and output layers 设定输入层、隐藏层和输出层的node数目</span></span><br><span class="line">        self.input_nodes = input_nodes</span><br><span class="line">        self.hidden_nodes = hidden_nodes</span><br><span class="line">        self.output_nodes = output_nodes</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set the learning rate</span></span><br><span class="line">        self.lr = learning_rate</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize weights，初始化权重和学习速率</span></span><br><span class="line">        <span class="comment"># 正态分布 第一个参数为均值（分布的中心center） 第二个参数为标准差（分布的宽度） 第三个为size</span></span><br><span class="line">        self.weights_input_to_hidden = np.random.normal( <span class="number">0.0</span>, self.input_nodes**<span class="number">-0.5</span>, (self.input_nodes, self.hidden_nodes) )</span><br><span class="line">        self.weights_hidden_to_output = np.random.normal( <span class="number">0.0</span>, self.hidden_nodes**<span class="number">-0.5</span>, (self.hidden_nodes, self.output_nodes) )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Activation function 隐藏层的激励函数为sigmoid函数</span></span><br><span class="line">        <span class="comment"># lambda语句创建一个匿名函数。冒号前面是传入参数，后面是一个处理传入参数的单行表达式</span></span><br><span class="line">        self.activation_function = <span class="keyword">lambda</span> x : <span class="number">1</span> / ( <span class="number">1</span> + np.exp(-x) )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, features, targets)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Arguments</span></span><br><span class="line"><span class="string">        ---------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        features: 2D array, each row is one data record, each column is a feature</span></span><br><span class="line"><span class="string">        targets: 1D array of target values</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># shape[0]表示第2维的长度 [1]表示第1维的长度</span></span><br><span class="line">        n_record = features.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># zeros(shape)返回一个给定形状的全0数组</span></span><br><span class="line">        delta_weights_i_h = np.zeros( self.weights_input_to_hidden.shape )</span><br><span class="line">        delta_weights_h_o = np.zeros( self.weights_hidden_to_output.shape )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播 Backward pass，使用梯度下降对权重进行更新 ###</span></span><br><span class="line">        <span class="comment"># 计算各权值w对整体误差产生的影响 通过用整体误差对各权值w求偏导求出</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> zip( features, targets ):</span><br><span class="line">            <span class="comment"># dot表示数组矩阵乘(一维数组是内积 以上维度是矩阵成绩) 矩阵mat类型的可以用点乘直接运算</span></span><br><span class="line">            hidden_inputs = np.dot( X, self.weights_input_to_hidden )</span><br><span class="line">            hidden_outputs = self.activation_function( hidden_inputs )</span><br><span class="line"></span><br><span class="line">            final_inputs = np.dot( hidden_outputs, self.weights_hidden_to_output )</span><br><span class="line">            final_outputs = final_inputs</span><br><span class="line"></span><br><span class="line">            error = y - final_outputs</span><br><span class="line">            <span class="comment"># 实际误差</span></span><br><span class="line">            output_error_term = error <span class="comment"># error * 1</span></span><br><span class="line">            <span class="comment"># hidden_error表示sigma(输出层误差*hidden_output权重)</span></span><br><span class="line">            hidden_error = np.dot( self.weights_hidden_to_output, output_error_term )</span><br><span class="line">            <span class="comment"># hidden_error_term表示隐含层的误差 = hidden_error*out(1-out)</span></span><br><span class="line">            hidden_error_term = hidden_error * hidden_outputs * (<span class="number">1</span> - hidden_outputs) <span class="comment"># f'(hidden_input)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算最终的偏导数值 X[:,None] = X 。即i</span></span><br><span class="line">            <span class="comment"># [:,None]的效果就是将二维数组按每行分割，最后形成一个三维数组</span></span><br><span class="line">            delta_weights_i_h += hidden_error_term * X[:,<span class="keyword">None</span>]</span><br><span class="line">            delta_weights_h_o += output_error_term * hidden_outputs[:,<span class="keyword">None</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新各层之间的权重w  w=w-学习率*误差</span></span><br><span class="line">        self.weights_input_to_hidden += self.lr * delta_weights_i_h/n_record</span><br><span class="line">        self.weights_hidden_to_output += self.lr * delta_weights_h_o/n_record</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行预测</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        <span class="comment">#### 实现向前传播 Implement the forward pass here ####</span></span><br><span class="line">        <span class="comment"># 隐藏层 Hidden layer</span></span><br><span class="line">        hidden_inputs = np.dot( features, self.weights_input_to_hidden )</span><br><span class="line">        hidden_output = self.activation_function( hidden_inputs )</span><br><span class="line">        <span class="comment"># 输出层 Output layer</span></span><br><span class="line">        final_inputs = np.dot( hidden_output, self.weights_hidden_to_output )</span><br><span class="line">        final_outputs = final_inputs</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MSE</span><span class="params">(y, Y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.mean( (y - Y)**<span class="number">2</span> )</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"><span class="comment"># 输入层 3个神经元</span></span><br><span class="line">inputs = np.array([[<span class="number">0.5</span>, <span class="number">-0.2</span>, <span class="number">0.1</span>]])</span><br><span class="line"><span class="comment"># 输出层 1个结果单元</span></span><br><span class="line">targets = np.array([[<span class="number">0.4</span>]])</span><br><span class="line"><span class="comment"># 每个输入神经元对应于每个隐藏层神经元的权值 （隐藏层有2个神经元）</span></span><br><span class="line">test_w_i_h = np.array([[<span class="number">0.1</span>, <span class="number">-0.2</span>],</span><br><span class="line">                       [<span class="number">0.4</span>, <span class="number">0.5</span>],</span><br><span class="line">                       [<span class="number">-0.3</span>, <span class="number">0.2</span>]])</span><br><span class="line"><span class="comment"># 隐藏层对输出层权值</span></span><br><span class="line">test_w_h_o = np.array([[<span class="number">0.3</span>],</span><br><span class="line">                       [<span class="number">-0.1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestMethods</span><span class="params">(unittest.TestCase)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">##########</span></span><br><span class="line">    <span class="comment"># Unit tests for data loading</span></span><br><span class="line">    <span class="comment">##########</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_data_path</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Test that file path to dataset has been unaltered</span></span><br><span class="line">        self.assertTrue(data_path.lower() == <span class="string">'bike-sharing-dataset/hour.csv'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_data_loaded</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Test that data frame loaded</span></span><br><span class="line">        self.assertTrue(isinstance(rides, pd.DataFrame))</span><br><span class="line"></span><br><span class="line">    <span class="comment">##########</span></span><br><span class="line">    <span class="comment"># Unit tests for network functionality</span></span><br><span class="line">    <span class="comment">##########</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_activation</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 设置各层神经元的数目</span></span><br><span class="line">        network = NeuralNetwork(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># Test that the activation function is a sigmoid</span></span><br><span class="line">        self.assertTrue(np.all(network.activation_function(<span class="number">0.5</span>) == <span class="number">1</span>/(<span class="number">1</span>+np.exp(<span class="number">-0.5</span>))))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Test that weights are updated correctly on training</span></span><br><span class="line">        network = NeuralNetwork(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0.5</span>)</span><br><span class="line">        network.weights_input_to_hidden = test_w_i_h.copy()</span><br><span class="line">        network.weights_hidden_to_output = test_w_h_o.copy()</span><br><span class="line"></span><br><span class="line">        network.train(inputs, targets)</span><br><span class="line">        <span class="comment">#allclose()函数用来检测两个矩阵是否相等</span></span><br><span class="line">        self.assertTrue(np.allclose(network.weights_hidden_to_output,</span><br><span class="line">                                    np.array([[ <span class="number">0.37275328</span>],</span><br><span class="line">                                              [<span class="number">-0.03172939</span>]])))</span><br><span class="line">        self.assertTrue(np.allclose(network.weights_input_to_hidden,</span><br><span class="line">                                    np.array([[ <span class="number">0.10562014</span>, <span class="number">-0.20185996</span>],</span><br><span class="line">                                              [<span class="number">0.39775194</span>, <span class="number">0.50074398</span>],</span><br><span class="line">                                              [<span class="number">-0.29887597</span>, <span class="number">0.19962801</span>]])))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Test correctness of run method</span></span><br><span class="line">        network = NeuralNetwork(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0.5</span>)</span><br><span class="line">        network.weights_input_to_hidden = test_w_i_h.copy()</span><br><span class="line">        network.weights_hidden_to_output = test_w_h_o.copy()</span><br><span class="line"></span><br><span class="line">        self.assertTrue(np.allclose(network.run(inputs), <span class="number">0.09998924</span>))</span><br><span class="line"></span><br><span class="line">suite = unittest.TestLoader().loadTestsFromModule(TestMethods())</span><br><span class="line">unittest.TextTestRunner().run(suite)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">### 设置超参数 ###</span></span><br><span class="line">iterations = <span class="number">2000</span></span><br><span class="line">learning_rate = <span class="number">0.8</span></span><br><span class="line">hidden_nodes = <span class="number">12</span> <span class="comment"># 12个隐藏层神经元</span></span><br><span class="line">output_nodes = <span class="number">1</span>  <span class="comment"># 输出1个神经元</span></span><br><span class="line"></span><br><span class="line">N_i = train_features.shape[<span class="number">1</span>]</span><br><span class="line">network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)</span><br><span class="line"></span><br><span class="line">losses = &#123;<span class="string">'train'</span>:[], <span class="string">'validation'</span>:[]&#125;</span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(iterations):</span><br><span class="line">    <span class="comment"># np.random.choice(a,b)从一个int数字或1维数组里随机选取内容，并将选取结果放入b维数组中返回。</span></span><br><span class="line">    batch = np.random.choice(train_features.index, size=<span class="number">128</span>)</span><br><span class="line">    <span class="comment"># .shape返回行列数 .size返回元素数</span></span><br><span class="line">    X, y = train_features.iloc[batch].values, train_targets.iloc[batch][<span class="string">'cnt'</span>]</span><br><span class="line">    <span class="comment"># 用训练集数据训练</span></span><br><span class="line">    network.train(X, y)</span><br><span class="line">    <span class="comment"># 计算当前模型对训练集的预测损失度 和 对验证集的预测损失度</span></span><br><span class="line">    train_loss = MSE(network.run(train_features).T, train_targets[<span class="string">'cnt'</span>].values)</span><br><span class="line">    <span class="comment"># run().T是将结果转置，如将1*m数组变成m*1数组</span></span><br><span class="line">    val_loss = MSE(network.run(val_features).T, val_targets[<span class="string">'cnt'</span>].values)</span><br><span class="line"></span><br><span class="line">    sys.stdout.write(<span class="string">"\rProgress: &#123;:2.1f&#125;"</span>.format(<span class="number">100</span> * ii/float(iterations)) \</span><br><span class="line">                     + <span class="string">"% ... Training loss: "</span> + str(train_loss)[:<span class="number">5</span>] \</span><br><span class="line">                     + <span class="string">" ... Validation loss: "</span> + str(val_loss)[:<span class="number">5</span>]+<span class="string">"\n"</span>)</span><br><span class="line">    <span class="comment"># &#123;:n.mf&#125;表示整数位n位，浮点位m位小数。 str()[n:m]表示字符串的[n,m-1)位</span></span><br><span class="line">    sys.stdout.flush()</span><br><span class="line"></span><br><span class="line">    losses[<span class="string">'train'</span>].append(train_loss)</span><br><span class="line">    losses[<span class="string">'validation'</span>].append(val_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成训练损失和验证损失的曲线图</span></span><br><span class="line">plt.plot(losses[<span class="string">'train'</span>], label=<span class="string">'Traning loss'</span>)</span><br><span class="line">plt.plot(losses[<span class="string">'validation'</span>], label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成预测数量和实际数量的曲线对比图</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 生成预测数据</span></span><br><span class="line">mean, std = scaled_feature[<span class="string">'cnt'</span>]</span><br><span class="line">predictions = network.run(test_features).T * std + mean</span><br><span class="line">ax.plot(predictions[<span class="number">0</span>], label=<span class="string">'Prediction'</span>)</span><br><span class="line">ax.plot((test_targets[<span class="string">'cnt'</span>] * std + mean).values, label=<span class="string">'Data'</span>)</span><br><span class="line"><span class="comment"># 设置x轴的范围</span></span><br><span class="line">ax.set_xlim(right=len(predictions))</span><br><span class="line">ax.legend()</span><br><span class="line">dates = pd.to_datetime(rides.loc[test_data.index][<span class="string">'dteday'</span>])</span><br><span class="line">dates = dates.apply(<span class="keyword">lambda</span> d: d.strftime(<span class="string">'%b %d'</span>))</span><br><span class="line"><span class="comment"># 设置x轴的标记点</span></span><br><span class="line">ax.set_xticks(np.arange(len(dates))[<span class="number">12</span>::<span class="number">24</span>])</span><br><span class="line"><span class="comment"># 设置x轴的标注文本</span></span><br><span class="line">_ = ax.set_xticklabels(dates[<span class="number">12</span>::<span class="number">24</span>], rotation=<span class="number">45</span>)</span><br><span class="line"><span class="comment"># plt才有show函数，ax没有show</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="comment"># 需要设置的参数：迭代次数、输入层神经元个数、隐藏层神经元个数、输出层神经元个数、学习率      #</span></span><br><span class="line"><span class="comment"># 需要传的参数：  输入神经元、输入层到隐藏层的权重、隐藏层到输出层的权重、输出层目标值神经元  #</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>本文来源：「想飞的小菜鸡」的个人网站  <a href="https://vodkazy.cn" target="_blank" rel="noopener">vodkazy.cn</a></p>
<p>版权声明：本文为「想飞的小菜鸡」的原创文章，采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请附上原文出处链接及本声明。</p>
<p>原文链接：<a href="https://vodkazy.cn/2018/05/17/搭建BP神经网络预测单车数量" target="_blank" rel="noopener">https://vodkazy.cn/2018/05/17/搭建BP神经网络预测单车数量</a></p>
</blockquote>

        </div>
      </article>
    </div>

	<!-- 打赏 -->
    <div class="reward">
	<div class="reward-button">赏 <span class="reward-code">
		<span class="alipay-code"> <img class="alipay-img wdp-appear" src="data:image/png;base64,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" data-original="/images/alipay.webp"><b>支付宝打赏</b> </span> 
		<span class="wechat-code"> <img class="wechat-img wdp-appear" src="data:image/png;base64,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" data-original="/images/weixin.webp"><b>微信打赏</b> </span> </span>
	</div>
	<p class="reward-notice">如果文章对你有帮助，欢迎点击上方按钮打赏作者，更多文章请访问<a href="https://vodkazy.cn" style="color:blue">想飞的小菜鸡</a></p>
	    <style>
		*,*:before,*:after {
			-webkit-box-sizing: border-box;
			-moz-box-sizing: border-box;
			-ms-box-sizing: border-box;
			box-sizing: border-box
		}

		.reward {
			padding: 5px 0
		}

		.reward .reward-notice {
			font-size: 14px;
			line-height: 14px;
			margin: 15px auto;
			text-align: center
		}

		.reward .reward-button {
			font-size: 28px;
			line-height: 58px;
			position: relative;
			display: block;
			width: 60px;
			height: 60px;
			margin: 0 auto;
			padding: 0;
			-webkit-user-select: none;
			text-align: center;
			vertical-align: middle;
			color: #fff;
			border: 1px solid #f1b60e;
			border-radius: 50%;
			background: #fccd60;
			background: -webkit-gradient(linear,left top,left bottom,color-stop(0,#fccd60),color-stop(100%,#fbae12),color-stop(100%,#2989d8),color-stop(100%,#207cca));
			background: -webkit-linear-gradient(top,#fccd60 0,#fbae12 100%,#2989d8 100%,#207cca 100%);
			background: linear-gradient(to bottom,#fccd60 0,#fbae12 100%,#2989d8 100%,#207cca 100%)
		}

		.reward .reward-code {
			position: absolute;
			top: -220px;
			left: 50%;
			display: none;
			width: 350px;
			height: 200px;
			margin-left: -175px;
			padding: 15px;
			border: 1px solid #e6e6e6;
			background: #fff;
			box-shadow: 0 1px 1px 1px #efefef
		}

		.reward .reward-button:hover .reward-code {
			display: block
		}

		.reward .reward-code span {
			display: inline-block;
			width: 150px;
			height: 150px
		}

		.reward .reward-code span.alipay-code {
			float: left
		}

		.reward .reward-code span.alipay-code a {
			padding: 0
		}

		.reward .reward-code span.wechat-code {
			float: right
		}

		.reward .reward-code img {
			display: inline-block;
			float: left;
			width: 150px;
			height: 150px;
			margin: 0 auto;
			border: 0
		}

		.reward .reward-code b {
			font-size: 14px;
			line-height: 26px;
			display: block;
			margin: 0;
			text-align: center;
			color: #666
		}

		.reward .reward-code b.notice {
			line-height: 2rem;
			margin-top: -1rem;
			color: #999
		}

		.reward .reward-code:after,.reward .reward-code:before {
			position: absolute;
			content: '';
			border: 10px solid transparent
		}

		.reward .reward-code:after {
			bottom: -19px;
			left: 50%;
			margin-left: -10px;
			border-top-color: #fff
		}

		.reward .reward-code:before {
			bottom: -20px;
			left: 50%;
			margin-left: -10px;
			border-top-color: #e6e6e6
		}
    </style>


    <!-- Pre or Next -->
    
	<div class="container">
           <ul class="pager">
    	     
      	     <li class="previous">
              <a href="/2018/05/18/codeforces-484-div2题解/" rel="prev">上一篇</a>
             </li>
           
           
              <li class="next">
              <a href="/2018/05/16/神经网络学习笔记/" rel="prev">下一篇</a>
            </li>
           
          </ul>
       </div>
   

    <!-- Valine无后端评论系统 -->   
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
    <div id="vcomments"></div>
    <script>
        new Valine({
		    el: '#vcomments' ,
		    appId: 'lH3VkMCd4MHaKtr2n2SRWdoi-MdYXbMMI',
		    appKey: '5aMXSY7b4KwnzfgpzLA0hPLv',
		    notify:true, 
		    verify:false, 
		    placeholder: '填写正确的邮箱和昵称才能收到我的回复哦       ٩( ^o^ )و  ' ,
		    avatar: 'retro'
		});
    </script>
    <!-- Valine无后端评论系统 -->  

  </div>
</div>
</div>

  <!-- Footer -->
  <!-- Footer -->
<footer class="site-info">
  <p>
    <span>想飞的小菜鸡 &copy; 2021</span>
    
      <span class="split">|</span>
      <span>照耀的Blog</span>
    
  </p>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
    本站访客数<span id="busuanzi_value_site_uv"></span>人次
    本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</footer>

  <!-- After footer scripts -->
  <!-- scripts -->
<script src="/js/app.js"></script>


 
  <!-- 使用 aotuload.js 引入看板娘 -->    
  <!-- //<script src="/js/assets/jquery.min.js?v=3.3.1"></script> -->   
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
  <!-- //<script src="/js/assets/jquery-ui.min.js?v=1.12.1"></script>   --> 
  <script src="https://cdn.jsdelivr.net/npm/jquery-ui-dist@1.12.1/jquery-ui.min.js"></script>
  <script src="/js/assets/autoload.js?v=1.4.2"></script>
  <!-- //<script src="https://live2d-cdn.fghrsh.net/assets/1.4.2/autoload.js></script> -->   
   


<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],e=void 0,0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>

</html>
